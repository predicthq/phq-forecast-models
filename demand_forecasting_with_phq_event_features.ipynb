{
 "cells": [
  {
   "block_group": "a4d43f0cdd59422587c1dfff85fade5b",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates demand forecasting enhancements using PredictHQ Event Features. It guides users through the key steps of feature engineering, model evaluation, and forecasting. \n",
    "\n",
    "A sample demand dataset and configuration file is provided. A valid `PHQ_ACCESS_TOKEN` is required for accessing PredictHQ Event Features from the [PredictHQ's APIs](https://docs.predicthq.com/api/overview). A set of pre-generated event feature is provided for demonstration purposes if a `PHQ_ACCESS_TOKEN` is unavailable."
   ]
  },
  {
   "block_group": "cbe8bfaf2b1942b19ce60dae5b4d805b",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "* [Settings](#settings)\n",
    "* [Load Demand and Configuration Files](#read_files)\n",
    "* [Beam Analysis and Feature Engineering](#create_beam_analysis)\n",
    "* [Model Evaluation and Comparison](#demand_forecast_evaluation)\n",
    "* [Model Creation](#model_creation)\n",
    "* [Forecasting](#forecating)"
   ]
  },
  {
   "block_group": "182cd6c37b5d400bb9cd75c177825b61",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "block_group": "7467b2b89535490cae31c631fe022831",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from phq import (\n",
    "    run_beam_analysis,\n",
    "    process_demand_data,\n",
    "    prepare_event_features,\n",
    "    prepare_time_trend_features,\n",
    "    prepare_forecast_features,\n",
    "    evaluate_forecast_model,\n",
    "    PhqForecastModel\n",
    ")\n",
    "\n",
    "# Suppress logging output from cmdstanpy\n",
    "logger = logging.getLogger(\"cmdstanpy\")\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "block_group": "8b476538cf014ad78460f27bda97cd99",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"settings\">Settings</h2>\n",
    "\n",
    "This section configures the environment and [PHQ_ACCESS_TOKEN]((https://docs.predicthq.com/getting-started/api-quickstart#create-an-access-token)) for accessing PredictHQ's APIs. The notebook supports two execution modes, controlled by the RUN_SETTING parameter:\n",
    "1. `RUN_SETTING = \"CSV_EVENT_FEATURES\"` – Runs without a `PHQ_ACCESS_TOKEN`, using pre-generated event feature files for the provided sample demand dataset and configuration file.\n",
    "2. `RUN_SETTING = \"API_EVENT_FEATURES\"` – Runs with a `PHQ_ACCESS_TOKEN`, using PredictHQ's APIs to generate PredictHQ Event Features for the provided demand dataset and configuration file. The demand dataset can be either the sample demand data or the user’s own dataset.\n",
    "\n",
    "Ensure that `PHQ_ACCESS_TOKEN` is set when selecting `\"API_EVENT_FEATURES\"`.\n",
    "\n"
   ]
  },
  {
   "block_group": "80d82258b6ce4aab89b1b67b4e931ce4",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the run setting to \"CSV_EVENT_FEATURES\" to use the sample csv files in the data folder or \"API_EVENT_FEATURES\" to use the PredictHQ's APIs\n",
    "RUN_SETTING = \"CSV_EVENT_FEATURES\"\n",
    "if RUN_SETTING == \"API_EVENT_FEATURES\":\n",
    "    # set the PHQ access token in the environment variable or replace \"XXXXXX\" with your access token\n",
    "    PHQ_ACCESS_TOKEN = os.environ.get(\"PHQ_ACCESS_TOKEN\") or \"XXXXXX\"\n",
    "\n",
    "if RUN_SETTING == \"CSV_EVENT_FEATURES\":\n",
    "    print(\"Running the notebook with provided sample demand and PredictHQ Event Features\")\n",
    "else:\n",
    "    print(f\"Running with PHQ_ACCESS_TOKEN\")\n",
    "\n",
    "os.makedirs(\"results/models\", exist_ok=True)"
   ]
  },
  {
   "block_group": "276397fa621549ecbb105461944e9325",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"read_files\">Load Demand and Configuration files</h2>\n",
    "\n",
    "This section loads the daily demand dataset and configuration settings. The demand dataset is stored as a CSV file with columns for `date` and `demand`. The configuration file provides metadata such as `lat`, `lon`, `industry`, and `name`, which are required in feature engineering step."
   ]
  },
  {
   "block_group": "1b318afbe9ef420b9915226038db70bc",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample daily demand data\n",
    "sample_demand_df = pd.read_csv(\"data/sample_demand.csv\")\n",
    "\n",
    "# Read the configuration file\n",
    "with open(\"data/sample_config.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "block_group": "395384700dd140309aaee69abaf29706",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"create_beam_analysis\">Beam Analysis and Feature Engineering</h2>\n",
    "\n",
    "This section prepares the PredictHQ Event Features and time trend features. The PredictHQ Event Features are prepared based on Feature Importance results from a Beam analysis. The time trend features are based on the time dates and historical demand values. Key steps include:\n",
    "- Running a **Beam Analysis** using PredictHQ's API if `RUN_SETTING = \"API_EVENT_FEATURES\"`.\n",
    "- Preparing demand data to handle missing values.\n",
    "- Preparing **PredictHQ Event Features**.\n",
    "- Preparing **time trend features**."
   ]
  },
  {
   "block_group": "27de842662414080841766145068d31a",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_SETTING == \"API_EVENT_FEATURES\":\n",
    "    # create an analysis and wait for it to complete\n",
    "    sample_beam_analysis_result = run_beam_analysis(\n",
    "        config[\"name\"],\n",
    "        config[\"lat\"],\n",
    "        config[\"lon\"],\n",
    "        sample_demand_df,\n",
    "        PHQ_ACCESS_TOKEN,\n",
    "        industry=config[\"industry\"],\n",
    "    )\n",
    "    sample_beam_analysis_id = sample_beam_analysis_result.analysis_id\n",
    "else:\n",
    "    sample_beam_analysis_id = \"csv_sample_beam_analysis_id\""
   ]
  },
  {
   "block_group": "583947c501ae4a74a7782f6581037bc2",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process demand dataset\n",
    "demand_df = process_demand_data(sample_demand_df)\n",
    "# Prepare PredictHQ Event Features\n",
    "if RUN_SETTING == \"API_EVENT_FEATURES\":\n",
    "    event_features_df = prepare_event_features(\n",
    "        sample_beam_analysis_id, PHQ_ACCESS_TOKEN\n",
    "    )\n",
    "else:\n",
    "    event_features_df = pd.read_csv(\"data/sample_event_features.csv\")\n",
    "    event_features_df[\"date\"] = pd.to_datetime(event_features_df[\"date\"])\n",
    "# Prepare time trend features\n",
    "time_trend_features_df = prepare_time_trend_features(demand_df)\n",
    "# Combine PredictHQ Event Features and time trend features\n",
    "combined_features_df = time_trend_features_df.merge(event_features_df, on=\"date\")"
   ]
  },
  {
   "block_group": "ebb3f6cf7b104a9298e6b4bb212b3f14",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"demand_forecast_evaluation\">Model Evaluation and Comparison</h2>\n",
    "\n",
    "The model performance is evaluated and compared with and without PredictHQ Event Features using **Mean Absolute Percentage Error (MAPE)**. The model evalution might take a few minutes depending on the size of the demand dataset."
   ]
  },
  {
   "block_group": "38d7ae0b9bc54b668c14bdce76267922",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast model evaluation with PredictHQ Event Features\n",
    "evaluation_results_phq = evaluate_forecast_model(combined_features_df, demand_df)\n",
    "\n",
    "# Forecast model evaluation without PredictHQ Event Features\n",
    "evaluation_results_baseline = evaluate_forecast_model(time_trend_features_df, demand_df)\n",
    "\n",
    "# Model performance comparison\n",
    "phq_mape = evaluation_results_phq[\"mape\"]\n",
    "baseline_mape = evaluation_results_baseline[\"mape\"]\n",
    "print(f\"MAPE for forecast model with PredictHQ Event Features: {phq_mape:.2f}\")\n",
    "print(f\"MAPE for forecast model without PredictHQ Event Features: {baseline_mape:.2f}\")\n",
    "print(f\"Relative MAPE improvements: {100 * (baseline_mape - phq_mape) / baseline_mape:.2f}%\")"
   ]
  },
  {
   "block_group": "cea7948fde25442d836596bd216d8d9f",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"model_creation\">Model Creation</h2>\n",
    "\n",
    "This section builds and saves the forecast model. The model is trained using event and time trend features and then saved."
   ]
  },
  {
   "block_group": "e392bc64f9244c6baa993d39c289084f",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecast model\n",
    "forecast_model = PhqForecastModel()\n",
    "forecast_model.fit(combined_features_df, demand_df)\n",
    "# Save forecast model\n",
    "joblib.dump(forecast_model, f\"results/models/model_{sample_beam_analysis_id}.pkl\")"
   ]
  },
  {
   "block_group": "09575898e1714d6b8fabdadbe549c6a4",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"forecating\">Forecasting</h2>\n",
    "\n",
    "This section prepares forecasting features and applies the trained model to predict future demand."
   ]
  },
  {
   "block_group": "e35111cd84634bd282a13cc464e69a29",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for forecasting\n",
    "FORECAST_HORIZON = 7\n",
    "\n",
    "if RUN_SETTING == \"API_EVENT_FEATURES\":\n",
    "    forecasting_features_df = prepare_forecast_features(\n",
    "        demand_df, sample_beam_analysis_id, FORECAST_HORIZON, PHQ_ACCESS_TOKEN\n",
    "    )\n",
    "else:\n",
    "    forecasting_features_df = pd.read_csv(\"data/sample_forecasting_features.csv\")\n",
    "# Forecast demand values\n",
    "predictions = forecast_model.predict(forecasting_features_df)"
   ]
  },
  {
   "block_group": "ecf25609b1ac44ea90fd3132f4080266",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"visuallization\">Visualization of forecasting results</h3>\n",
    "\n",
    "The forecasting results are visualized to compare historical demand with forecasted demand values."
   ]
  },
  {
   "block_group": "01703d0c15724b1a881659240fa611c3",
   "cell_type": "code",
   "content_dependencies": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=sample_demand_df[\"date\"],\n",
    "        y=sample_demand_df[\"demand\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Actual\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=forecasting_features_df[\"date\"],\n",
    "        y=predictions,\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Forecast\",\n",
    "    )\n",
    ")\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=f'Forecast results for the next {FORECAST_HORIZON} days',\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Demand\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
